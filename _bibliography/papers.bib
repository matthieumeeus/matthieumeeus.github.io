---
---

@inproceedings{meeus2024did,
  title={Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models},
  author={Meeus, Matthieu and Jain, Shubham and Rei, Marek and de Montjoye, Yves-Alexandre},
  booktitle={33rd USENIX Security Symposium (USENIX Security 24)},
  abbr={USENIX Security},
  pages={2369--2385},
  year={2024},
  selected={true},
  tldr={TLDR; Given a pretrained LLM and a document, can I infer whether the document was used to train the LLM?
            First, we rely on the collection of documents which we know have been used to train the LLM (members) and documents made available after the model release data (non-members).
            We then query the LLM on both members and non-members for token-level probabilities and train a classifier to predict binary membership.
            Spoiler: It's harder than you think!},
  link={https://arxiv.org/pdf/2310.15007},
  code={https://github.com/computationalprivacy/document-level-membership-inference},
  press={Press coverage in [Le Monde](https://www.lemonde.fr/sciences/article/2023/11/16/comment-savoir-si-un-contenu-a-ete-utilise-par-une-intelligence-artificielle_6200425_1650684.html).}
}

@inproceedings{meeuscopyright,
  title={Copyright Traps for Large Language Models},
  author={Meeus, Matthieu and Shilov, Igor and Faysse, Manuel and de Montjoye, Yves-Alexandre},
  booktitle={Forty-first International Conference on Machine Learning},
  abbr={ICML},
  year={2024},
  selected={true}
}

@inproceedings{meeus2023achilles,
  title={Achillesâ€™ Heels: Vulnerable Record Identification in Synthetic Data Publishing},
  author={Meeus, Matthieu and Guepin, Florent and Cre{\c{t}}u, Ana-Maria and de Montjoye, Yves-Alexandre},
  booktitle={European Symposium on Research in Computer Security},
  abbr={ESORICS},
  pages={380--399},
  year={2023},
  organization={Springer},
  selected={true}
}

@inproceedings{guepin2023synthetic,
  title={Synthetic Is All You Need: Removing the Auxiliary Data Assumption for Membership Inference Attacks Against Synthetic Data},
  author={Gu{\'e}pin, Florent and Meeus, Matthieu and Cre{\c{t}}u, Ana-Maria and de Montjoye, Yves-Alexandre},
  booktitle={European Symposium on Research in Computer Security},
  pages={182--198},
  year={2023},
  abbr={ESORICS Workshop},
  organization={Springer}
}

@article{meeus2024inherent,
  title={Inherent Challenges of Post-Hoc Membership Inference for Large Language Models},
  author={Meeus, Matthieu and Jain, Shubham and Rei, Marek and de Montjoye, Yves-Alexandre},
  journal={arXiv preprint arXiv:2406.17975},
  abbr={Preprint},
  year={2024}
}

@article{shilov2024mosaic,
  title={Mosaic Memory: Fuzzy Duplication in Copyright Traps for Large Language Models},
  author={Shilov, Igor and Meeus, Matthieu and de Montjoye, Yves-Alexandre},
  journal={arXiv preprint arXiv:2405.15523},
  abbr={Preprint},
  year={2024}
}

@article{meeus2023concerns,
  title={Concerns about using a digital mask to safeguard patient privacy},
  author={Meeus, Matthieu and Jain, Shubham and de Montjoye, Yves-Alexandre},
  journal={Nature Medicine},
  volume={29},
  number={7},
  pages={1658--1659},
  year={2023},
  publisher={Nature Publishing Group US New York},
  selected={true},
  abbr={Nature Medicine}
}

@article{guepin2024lost,
  title={Lost in the Averages: A New Specific Setup to Evaluate Membership Inference Attacks Against Machine Learning Models},
  author={Gu{\'e}pin, Florent and Kr{\v{c}}o, Nata{\v{s}}a and Meeus, Matthieu and de Montjoye, Yves-Alexandre},
  journal={arXiv preprint arXiv:2405.15423},
  abbr={Preprint},
  year={2024}
}