<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Matthieu Meeus </title> <meta name="author" content="Matthieu Meeus"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://matthieumeeus.github.io/publications/"> <script src="/assets/js/theme.js?de542d7f9acf23bc76f087c40112a4e8"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Matthieu <span class="font-weight-bold">Meeus</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p>The most updated information is available on <a href="https://scholar.google.com/citations?user=QaEzyhEAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google Scholar</a>.</p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML Workshop</abbr> </div> <div id="meeus2025counterfactual" class="col-sm-8"> <div class="title">Counterfactual Influence as a Distributional Quantity</div> <div class="author"> Matthieu Meeus, Igor Shilov, Georgios Kaissis, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>Workshop on The Impact of Memorization on Trustworthy Foundation Models (MemFM) @ ICML 2025</em>, 2025 </div> <div class="periodical"> </div> <div class="press"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/pdf/2506.20481" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>TLDR; We study how memorization in ML models can be better understood by looking at the entire influence distribution rather than self-influence alone.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Neurips</abbr> </div> <div id="hayes2025strong" class="col-sm-8"> <div class="title">Strong Membership Inference Attacks on Massive Datasets and (Moderately) Large Language Models</div> <div class="author"> Jamie Hayes, Ilia Shumailov, Christopher A Choquette-Choo, Matthew Jagielski, George Kaissis, Katherine Lee, Milad Nasr, Sahra Ghalebikesabi, Niloofar Mireshghallah, Meenatchi Sundaram Mutu Selva Annamalai, and  others </div> <div class="periodical"> <em>Neural Information Processing Systems</em>, 2025 </div> <div class="periodical"> </div> <div class="press"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/pdf/2505.18773" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>TLDR; We run shadow-modeling based MIAs against LLM pretraining, studying how well attacks can perform when adversaries have strong computational power and how vulnerability changes with the setup/differs from other privacy metrics.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> </div> <div id="yang2025alignment" class="col-sm-8"> <div class="title">Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses</div> <div class="author"> Xiaoxue Yang, Bozhidar Stevanoski, Matthieu Meeus, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>arXiv preprint arXiv:2505.15738</em>, 2025 </div> <div class="periodical"> </div> <div class="press"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/pdf/2505.15738" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/computationalprivacy/checkpoint-gcg" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>TLDR; We take the perspective of a strong adversary to stress-test alignment based defenses against prompt injection attacks and jailbreaking. We find that successful attacks almost always exist, suggesting that alignment-based defenses are not robust against every improving attacks in the future.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> </div> <div id="meeus2025canary" class="col-sm-8"> <div class="title">The Canary’s Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text</div> <div class="author"> Matthieu Meeus, Lukas Wutschitz, Santiago Zanella-Béguelin, Shruti Tople, and Reza Shokri </div> <div class="periodical"> <em></em> 2025 </div> <div class="periodical"> </div> <div class="press"> <p> </p> <p>Work done during my internship at Microsoft Research.</p> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/abs/2502.14921" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/microsoft/dp-transformers/tree/main/research" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>TLDR; We propose the first privacy auditing pipeline for synthetic text. We implement different MIAs just based on access to the text and find that canaries with low-perplexity-prefix and high-perplexity-suffix are the most vulnerable.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">SaTML</abbr> </div> <div id="meeus2024inherent" class="col-sm-8"> <div class="title">SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How to Fix It)</div> <div class="author"> Matthieu Meeus, Shilov Igor, Shubham Jain, Manuel Faysse, Marek Rei, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>IEEE Conference on Secure and Trustworthy Machine Learning (SaTML 2025)</em>, 2025 </div> <div class="periodical"> </div> <div class="press"> <p> </p> <p>Received Best Paper Award at SaTML 2025.</p> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/pdf/2406.17975" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/computationalprivacy/mia_llms_benchmark" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>TLDR; We wrote an SoK on recent developments in MIAs against LLMs. We discuss how things have evolved recently, show popular evaluation setups to be flawed, and examine solutions going forward.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> </div> <div id="meeus2024chocollama" class="col-sm-8"> <div class="title">ChocoLlama: Lessons Learned From Teaching Llamas Dutch</div> <div class="author"> Matthieu Meeus, Anthony Rathé, François Remy, Pieter Delobelle, Jens-Joris Decorte, and Thomas Demeester </div> <div class="periodical"> <em>arXiv preprint arXiv:2412.07633</em>, 2024 </div> <div class="periodical"> </div> <div class="press"> <p> </p> <p>All 6 models are available on <a href="https://huggingface.co/ChocoLlama" rel="external nofollow noopener" target="_blank">HuggingFace</a>. Press coverage in Flemish newspaper <a href="https://www.tijd.be/ondernemen/technologie/computerwetenschappers-bouwen-vlaams-ai-model-chocollama/10585956.html" rel="external nofollow noopener" target="_blank">De Tijd</a>.</p> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/pdf/2412.07633" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/ChocoLlamaModel/ChocoLlama" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>TLDR; We further pretrain Llama-2/3 on Dutch data, and release a family of 6 open-source LLMs. We elaborate on our learnings in the paper (modifying the tokenizer, using LoRA at scale for language adaptation, pretraining versus posttraining, benchmarking).</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> </div> <div id="shilov2024mosaic" class="col-sm-8"> <div class="title">The Mosaic Memory of Large Language Models</div> <div class="author"> Igor Shilov, Matthieu Meeus, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>arXiv preprint arXiv:2405.15523</em>, 2024 </div> <div class="periodical"> </div> <div class="press"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2405.15523" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> </div> <div id="guepin2024lost" class="col-sm-8"> <div class="title">Lost in the Averages: A New Specific Setup to Evaluate Membership Inference Attacks Against Machine Learning Models</div> <div class="author"> Florent Guépin, Nataša Krčo, Matthieu Meeus, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>arXiv preprint arXiv:2405.15423</em>, 2024 </div> <div class="periodical"> </div> <div class="press"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2405.15423" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">USENIX Security</abbr> </div> <div id="meeus2024did" class="col-sm-8"> <div class="title">Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models</div> <div class="author"> Matthieu Meeus, Shubham Jain, Marek Rei, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>In 33rd USENIX Security Symposium (USENIX Security 24)</em>, 2024 </div> <div class="periodical"> </div> <div class="press"> <p> </p> <p>Press coverage in <a href="https://www.lemonde.fr/sciences/article/2023/11/16/comment-savoir-si-un-contenu-a-ete-utilise-par-une-intelligence-artificielle_6200425_1650684.html" rel="external nofollow noopener" target="_blank">Le Monde</a>.</p> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/pdf/2310.15007" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/computationalprivacy/document-level-membership-inference" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>TLDR; Given a pretrained LLM and a document, can I infer whether the document was used to train the LLM? First, we rely on the collection of documents which we know have been used to train the LLM (members) and documents made available after the model release data (non-members). We then query the LLM on both members and non-members for token-level probabilities and train a classifier to predict binary membership. Spoiler: It’s harder than you think!</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> </div> <div id="meeuscopyright" class="col-sm-8"> <div class="title">Copyright Traps for Large Language Models</div> <div class="author"> Matthieu Meeus, Igor Shilov, Manuel Faysse, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>In Forty-first International Conference on Machine Learning</em>, 2024 </div> <div class="periodical"> </div> <div class="press"> <p> </p> <p>Press coverage in <a href="https://www.technologyreview.com/2024/07/25/1095347/a-new-tool-for-copyright-holders-can-show-if-their-work-is-in-ai-training-data/" rel="external nofollow noopener" target="_blank">MIT Technology Review</a> and <a href="https://www.nature.com/articles/d41586-024-02599-9" rel="external nofollow noopener" target="_blank">Nature News</a>.</p> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/pdf/2402.09363" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/computationalprivacy/copyright-traps" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>TLDR; We add copyright traps to original content. These are highly unique sequences that, if an LLM were to be trained on it, we would be able to tell through how the LLM reacts to our injected trap. We inject a variety of traps into the pretraining dataset of the real-world 1.3B CroissantLLM trained from scratch, and find that copyright traps indeed enable content detectability.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ESORICS</abbr> </div> <div id="meeus2023achilles" class="col-sm-8"> <div class="title">Achilles’ Heels: Vulnerable Record Identification in Synthetic Data Publishing</div> <div class="author"> Matthieu Meeus, Florent Guepin, Ana-Maria Creţu, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>In European Symposium on Research in Computer Security</em>, 2023 </div> <div class="periodical"> </div> <div class="press"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/pdf/2306.10308" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/computationalprivacy/MIA-synthetic" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>TLDR; We audit the privacy risk of synthetic tabular data through Membership Inference Attacks (MIAs). For this, we are most concerned about the worst-case risk - so we propose a method to identify the most at-risk data records in a dataset. We show that our vulnerable record identification method beats previously used, ad-hoc outlier detection mechanisms significantly.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ESORICS Workshop</abbr> </div> <div id="guepin2023synthetic" class="col-sm-8"> <div class="title">Synthetic Is All You Need: Removing the Auxiliary Data Assumption for Membership Inference Attacks Against Synthetic Data</div> <div class="author"> Florent Guépin, Matthieu Meeus, Ana-Maria Creţu, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>In European Symposium on Research in Computer Security</em>, 2023 </div> <div class="periodical"> </div> <div class="press"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://arxiv.org/pdf/2307.01701" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/computationalprivacy/MIA-synthetic" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>TLDR; In Membership Inference Attacks (MIAs) against synthetic data, we typically assume the attacker to have access to some auxiliary data (from the same distribution as the real training data). In practice, this is not that realistic, especially for use cases typically suggested for synthetic data. We here examine what happens to the MIA performance when we use the released synthetic itself as a replacement for the auxiliary dataset to build shadow-modeling based MIAs. Spoiler: MIAs still work, but with a substantial drop compared to real auxiliary data. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Nature Medicine</abbr> </div> <div id="meeus2023concerns" class="col-sm-8"> <div class="title">Concerns about using a digital mask to safeguard patient privacy</div> <div class="author"> Matthieu Meeus, Shubham Jain, and Yves-Alexandre Montjoye </div> <div class="periodical"> <em>Nature Medicine</em>, 2023 </div> <div class="periodical"> </div> <div class="press"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://www.nature.com/articles/s41591-023-02439-9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/computationalprivacy/unmask" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>TLDR; A widely covered Nature paper introduces a Digital Mask (DM), an ’anonymization’ algorithm to be applied to facial images of patients. Reportedly, the mask would irreversibly erase all identifiable features while retaining the information necessary for medical diagnosis. We show their setup to evaluate the anonymization provided by the DM to be seriously flawed, and show that in a proper setup, the risk of identification increases by 100X.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Matthieu Meeus. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>